# `nf-core/demo`

[`nf-core/demo`](https://nf-co.re/demo/) is a simple nf-core style bioinformatics pipeline for workshops and demonstrations.

It was created using the nf-core template and is designed to run quickly and demonstrate customization options.

<figure class="excalidraw">
--8<-- "docs/nf_customize/img/subway.excalidraw.svg"
</figure>

The [`nf-core/demo`](https://nf-co.re/demo/) pipeline consists of three processes:

-   ([`FASTQC`](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/)): Read QC
-   ([`FASTP`](https://github.com/OpenGene/fastp)): Adapter and quality trimming
-   ([`MULTIQC`](http://multiqc.info/)): Present QC for raw reads

[`nf-core/demo`](https://nf-co.re/demo/) takes a samplesheet that contains paths to fastq files as an input and will produce four output folders:

-   `fastqc/`
    -   `*_fastqc.html`: FastQC report containing quality metrics.
    -   `*_fastqc.zip`: Zip archive containing the FastQC report, tab-delimited data file and plot images.
-   `fastp/`
    -   `*.fastp.html`: Trimming report in html format.
    -   `*.fastp.json`: Trimming report in json format.
    -   `*.fastp.log`: Trimming log file.
    -   `*.fastq.gz`: If --save_trimmed
-   `multiqc/`
    -   `multiqc_report.html`: a standalone HTML file that can be viewed in your web browser.
    -   `multiqc_data/`: directory containing parsed statistics from the different tools used in the pipeline.
    -   `multiqc_plots/`: directory containing static images from the report in various formats.
-   `pipeline_info/`
    -   Reports generated by Nextflow
    -   Reports generated by nf-core
    -   Parameters file

To help you understand the expectations for running every nf-core pipelines, they come with extensive documentation about the pipeline, its parameters, its usage, and its outputs. The documentation for the `nf-core/demo` pipeline [here](https://nf-co.re/demo/docs/usage).

## Your first `nf-core/demo` execution command

Before running any pipeline you will need to check if there are any parameters that are required.

You can view these on the parameters page of the pipeline.

By viewing the [parameters page of the `nf-core/demo` pipeline](https://nf-co.re/demo/dev/parameters), you can see that requires two parameters (`--input` and `--outdir`) to run.

Without these, the pipeline will not launch and nextflow will throw an error.

### `--input`

The `--input` parameter requires a path to comma-separated file containing information about the samples in the experiment.

```bash
--input 'path/to/samplesheet.csv'
```

Using the nf-core/demo usage documentation, you can see that it requires a comma-separated file (`.csv`) that contains 3 columns and a header row. The samplesheet file may consist of both single- and paired-end data may look something like the one below.

This is for 3 samples:

```csv title="samplesheet.csv"
sample,fastq_1,fastq_2
SAMPLE1_PE,path/to/sample1_R1.fastq.gz,path/to/sample1_R2.fastq.gz
SAMPLE2_PE,path/to/sample2_R1.fastq.gz,path/to/sample2_R2.fastq.gz
SAMPLE3_SE,path/to/sample3_R1.fastq.gz,
```

The pipeline will auto-detect whether a sample is single- or paired-end and if a sample has been sequenced more than once using the information provided in the samplesheet.

!!! question "Exercise"

    Create a samplesheet named `samplesheet.csv` for the pair end reads for samples gut, liver, and lung in the `data` folder.

    First, create the `samplesheet.csv`:

    ```bash
    code samplesheet.csv
    ```

    Next, add the header line, and for each sample, an id and the complete paths to the forward and reverse reads:

    ```csv title="samplesheet.csv"
    sample,fastq_1,fastq_2
    gut,/workspace/gitpod/nf-customize/data/gut_1.fq.gz,/workspace/gitpod/nf-customize/data/gut_2.fq.gz
    liver,/workspace/gitpod/nf-customize/data/liver_1.fq.gz,/workspace/gitpod/nf-customize/data/liver_2.fq.gz
    lung,/workspace/gitpod/nf-customize/data/lung_1.fq.gz,/workspace/gitpod/nf-customize/data/lung_2.fq.gz
    ```

    **Make sure it is saved in your working directory (`/workspace/gitpod/nf-customize/`)**

### `--outdir`

The `--output` parameter is used to name the output directory where the results will be saved and takes a string as input. You do not need to create this folder before you run the pipeline.

```bash
--output results
```

!!! question "Exercise"

    Execute the `nf-core/demo` pipeline with your new samplesheet as an input and an output directory named `results`"

    ```bash
    nextflow run nf-core/demo -r dev --input samplesheet.csv --outdir results
    ```

The previous exercise is expected to fail as the software required to run each process is not available in the Gitpod environment.

```console
ERROR ~ Error executing process > 'NFCORE_DEMO:DEMO:FASTP (sample1)'

Caused by:
  Process `NFCORE_DEMO:DEMO:FASTP (sample1)` terminated with an error exit status (127)
<truncated>
```

Fortunately, nf-core pipelines come packed with directives for containers and environments that can be flexibly enabled during execution.

### Profiles

Configuration files can contain the definition of one or more profiles. A profile is a set of configuration attributes that can be selected during pipeline execution by using the `-profile` command line option.

```bash
-profile <profile name>
```

Configuration profiles are defined by using the special scope`profiles`, which group the attributes that belong to the same profile using a common prefix. For example:

```
process.cpus = 1

profiles {
  foo {
    process.memory = '2 GB'
  }

  bar {
    process.memory = '4 GB'
  }
}
```

nf-core pipelines come with a series of profiles for running the pipelines using different software (e.g., Docker, Singularity, and Conda).

Here, you will need add the `singularity` profile to our execution command, which will download software images to run each process for us.

!!! Exercise

    Execute the command again, but this time with the singularity profile:

    ```bash
    nextflow run nf-core/demo -r dev --input samplesheet.csv --outdir results -profile singularity
    ```

    The `nf-core/demo` pipeline should now run successfully!

Every nf-core pipeline also comes with a `test` profile. This is a minimal set of configuration settings for the pipeline to run using a small test dataset that is hosted on the [nf-core/test-datasets](https://github.com/nf-core/test-datasets) repository.

It can be used for performing test(s) run of nf-core pipeline on your infrastructure, before using your own data.
